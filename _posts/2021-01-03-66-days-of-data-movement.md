---
layout: posts
title: My 66 days of Data journey 
excerpt: For me, 2021 will be a year of Data Science. Having developed software for a while now, I've always brushed it aside as something in my forever to-do list.
modified: 2021-01-03
date: 2021-01-03
tags: [Data Science, 66 Days of Data, diverge]
header: 
  overlay_image: /images/66-days-of-data/markus-spiske-iar-afb0qqw-unsplash.jpg
  caption: "Photo credit: [**Unsplash**](https://unsplash.com)"
comments: true
published: true
---

<section id="table-of-contents" class="toc">
  <header>
    <h3>Overview</h3>
  </header>
  <div id="drawer" markdown="1">
  *  Auto generated table of contents
  {:toc}
  </div>
</section>

[#66daysofdata](https://www.youtube.com/watch?v=qV_AlRwhI3I&t=24s) courtesy of [Ken Jee](https://kennethjee.com/)

For me, 2021 will be a year of Data Science. Having developed software for a while now, I've always brushed it aside as something in my forever to-do list.

So to keep the motivation up, I have joined the #66daysofdata movement, courtesy of the awesome Ken Jee. Here's hoping that the collective motivation of this dedicated bunch will help me reach my data goals this year.

## Day 1 - Introduction to Data Science
Because everybody starts somewhere, to kick start Day 1, [I have used this concise introduction](https://lnkd.in/gYKqfkg) to help me get my bearings.

As this journey unravels, I hope to have some clarity to enable me to focus on a field of data science that speaks to me.

## Day 2 - Update data to AWS S3
When building data applications it is inevitable that to be dealing with large amounts of data. I have currently leveraged AWS to build cloud native applications, so I will be looking at AWS S3 to enable me to do so.

I looked at the Python library [boto3](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/s3.html?highlight=create_multipart_upload#s3) to move files to S3 buckets as the destination for our data collection. For files up to 5GiB I can use S3 Put however for larger files up to 5TiB, S3 Multipart upload is required. Here's the [overview for S3 multipart uploads](https://docs.aws.amazon.com/AmazonS3/latest/dev/mpuoverview.html) for future reference.

## Day 3 - WTH is a Data Pipeline?

What is a Data Pipeline, why do we need it and what is the difference compared to traditional ETL processing?

I thought it best to learn about the high level constructs first before diving deeper...

Here is a clear and [concise explanation c/o Anshul](https://lnkd.in/gr93_Bx)

Thanks, it's just a 10 minute video, but it's gold.

## Day 4 & 5 - Data Science: The Big Picture
My [Pluralsight](https://app.pluralsight.com) subscription has many courses dedicated to Data Science, and I know it's not that well known, however, in amongst all the software development courses that it is well known for are many topics of everything Data Science targeting students of all levels.

The first one I took, [Data Science: The Big Picture](https://app.pluralsight.com/library/courses/data-science-big-picture) is a beginner level course, by [Matthew Renze](https://app.pluralsight.com/profile/author/matthew-renze?aid=701j0000001heIrAAI). It talks about what the common applications are for Data Science, and how pervasive it has become today.

It discusses how the Internet of Things have caused an explosion of data. It talks about Big Data and how the data that we create and store doubles every 2 years. It also covers the journey from Artificial Intelligence to Machine Learning through to Deep Learning. This is very interesting to me,  specially when he discusses practical examples of how these are applied in real life.

## Day 6 & 7

## Resources
- [What is the #66DaysOfData](https://www.youtube.com/watch?v=qV_AlRwhI3I&t){:target="_blank"}?