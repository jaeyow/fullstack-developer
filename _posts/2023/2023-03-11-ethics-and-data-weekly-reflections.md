---
layout: posts
title: Ethics in Data, Weekly Reflections 
excerpt: Provided in 6 weekly installments, we will cover current and relevant topics relating to ethics in data 
modified: 2023-03-10
date: 2023-03-10
tags: [AI, ML, Data, Ethics, Data Ethics, Fairness]
header: 
  overlay_image: /images/ethics-and-data-weekly-reflections/piret-ilver-98MbUldcDJY-unsplash.jpg
  caption: "Photo credit: [**Unsplash**](https://unsplash.com)"
comments: true
published: true
---

<section id="table-of-contents">
  <header>
    <h3>Overview</h3>
  </header>
  <div id="drawer" markdown="1">
  *  Auto generated table of contents
  {:toc}
  </div>
</section>

## Introduction
In the next 6 weeks, I will be writing about relevant topics pertaining to ethics in data. Being a software developer, AI and ML practitioner, I need to exert more effort to understand the ethical implications of the industry that I belong to and the work that I do.

## Week 1: Code Completion Tooling

In June 2021, [GitHub released Copilot](https://github.com/features/copilot), a code completion tool that uses machine learning to write code for you. Marketed as an **AI Pair Programmer**, it's intended to help developers write code faster. Copilot has been trained on billions of lines of code from various sources, including public Open Source projects in GitHub and other public repositories.

<figure>
	<a href="../images/ethics-and-data-weekly-reflections/blog_image_copilot.png"><img src="../images/ethics-and-data-weekly-reflections/blog_image_copilot.png"></a><figcaption>Amazon CodeWhisperer and Google Copilot</figcaption>
</figure>

Nearly a year to the date, Amazon released a preview of **[Amazon Code Whisperer](https://aws.amazon.com/codewhisperer/)**, a similar tool to Copilot.  

As a software developer, I am excited about the possibilities of these tools. I am always on the lookout for tools that can help me write better code. As awesome as these tools are, I am also concerned about their ethical implications. Being trained on [Open Source code](https://en.wikipedia.org/wiki/Open_source), what will this mean to the source code that it has generated?

From the point of view of [GitHub](https://github.com/) and [Amazon](https://aws.amazon.com/), it makes great business sense, as it uses open source code freely available on the web. It's akin to a Mining company that mines and exploits resources for free, then selling it for a huge profit. 

I am almost certain that the original authors did not intend their code to be used in this manner. There is a [class action](https://githubcopilotlitigation.com/) filed against Copilot on behalf of the millions of GitHub users whose code was used to train the tool. The outcome of this litigation could have significant implications for the these **products**, the millions of **developers** already using them, and the source code **authors** of code used to train these products.

## Week 2: Surveillance technology to spy on workers?

Let's start this second week reflection by [watching this short video](https://www.facebook.com/TheEconomist/videos/1305206572937997/). It's about a company called [Humanyze](https://humanyze.com/), where they use digital badges to track the movements of employees in the workplace. Calling their technology `People Analytics`, they claim that it can help companies improve productivity and employee engagement. The device hears and knows everything you are doing, for every second one spends in the office.

<figure>
	<a href="../images/ethics-and-data-weekly-reflections/ethics-surveillance-workers.png"><img src="../images/ethics-and-data-weekly-reflections/ethics-surveillance-workers.png"></a><figcaption>People Analytics using digital badges</figcaption>
</figure>

It is an older video, however this technology is still being used by thousands of organisations today. It begs the question, is this ethical? There are few ways to dissect this question, but in this instance let's use a simple framework to help us come up with an answer.

The framework to help us answer this ethical dilemma is called [Deontological Framework](https://ethicsunwrapped.utexas.edu/glossary/deontology). It is actually quite straightforward to apply as it only requires people to follow the rules and simply do their duty. With this framework, we don't even have to think about the consequences of our decisions.  

For example, in this scenario, as long as the company can prove that they have consent of the workers using the device, and not against anything illegal, then it is ethical. Humanyze claims that all the data collected are not `listened` for content, but rather only for looking in patterns of interaction, and no identifiable information is collected at all. As to the organisations using these badges in their offices, they come from a good place, of not putting their employees under `surveillance`, but rather helping them enjoy their work more. 

All the data collected is 100% anonymous. It helps identify and diagnose issues in the workplace, those that can affect performance and employee engagement. It can then quantify all the costs, opportunities and risks, so that the company can understand the impact of the changes and their decisions.  

Thousands of organisations have reported significant increases in productivity and employee retention across the board, so they must be doing something right.

What do you think, do you think it is ethical? 

<!--## Week 3: Coming soon...

## Week 4: Coming soon...

## Week 5: Coming soon...

## Week 6: Coming soon... -->

